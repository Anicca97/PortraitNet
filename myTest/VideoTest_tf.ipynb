{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"-1\"\n",
    "import time\n",
    "import json\n",
    "import argparse\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import graph_util\n",
    "from easydict import EasyDict as edict\n",
    "from yaml import load\n",
    "\n",
    "import sys\n",
    "sys.path.append('../data/')\n",
    "sys.path.append('../model/')\n",
    "\n",
    "from datasets import Human\n",
    "from data_aug import Normalize_Img, Anti_Normalize_Img\n",
    "\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "% matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (5,5)\n",
    "\n",
    "# from torchsummart import summary\n",
    "# import onnxruntime\n",
    "# from onnxruntime.datasets import get_example\n",
    "# import onnx\n",
    "\n",
    "# np.set_printoptions(threshold=np.inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(img,fw ,fh, background, imgW, imgH, mean, std, ):\n",
    "    \n",
    "    background = cv2.resize(background, (fw, fh))\n",
    "\n",
    "    # result_w, result_h=fw, fh\n",
    "\n",
    "    # print(\"video is saved in \" + videoOut)\n",
    "    # video = cv2.VideoWriter(videoOut, cv2.VideoWriter_fourcc(*'mp4v'), 30, (result_w, result_h))\n",
    "    \n",
    "    # if not success or img is None:\n",
    "    #     vidcap.release()\n",
    "    #     break\n",
    "    # img_orig = cv2.resize( img, (mid_w ,mid_h), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "    img_orig = np.copy(img)\n",
    "    img = cv2.resize(img, (imgW, imgH),interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "    img = img.astype(np.float32)\n",
    "    for j in range(3):\n",
    "        img[:, :, j] -= mean[j]\n",
    "    for j in range(3):\n",
    "        img[:, :, j] /= std[j]\n",
    "\n",
    "    img /= 255\n",
    "    img = img.transpose((2, 0, 1))\n",
    "    img_tensor = torch.from_numpy(img)\n",
    "    img_tensor = torch.unsqueeze(img_tensor, 0)  # add a batch dimension\n",
    "    return img_orig, background, img_tensor\n",
    "\n",
    "def padding_img(img_ori, size=224, color=128):\n",
    "    height = img_ori.shape[0]\n",
    "    width = img_ori.shape[1]\n",
    "    img = np.zeros((max(height, width), max(height, width), 3)) + color\n",
    "    \n",
    "    if (height > width):\n",
    "        padding = int((height-width)/2)\n",
    "        img[:, padding:padding+width, :] = img_ori\n",
    "    else:\n",
    "        padding = int((width-height)/2)\n",
    "        img[padding:padding+height, :, :] = img_ori\n",
    "        \n",
    "    img = np.uint8(img)\n",
    "    img = cv2.resize(img, (size, size), interpolation=cv2.INTER_CUBIC)\n",
    "    return np.array(img, dtype=np.float32)\n",
    "\n",
    "def resize_padding(image, dstshape, padValue=0):\n",
    "    height, width, _ = image.shape\n",
    "    ratio = float(width)/height # ratio = (width:height)\n",
    "    dst_width = int(min(dstshape[1]*ratio, dstshape[0]))\n",
    "    dst_height = int(min(dstshape[0]/ratio, dstshape[1]))\n",
    "    origin = [int((dstshape[1] - dst_height)/2), int((dstshape[0] - dst_width)/2)]\n",
    "    if len(image.shape)==3:\n",
    "        image_resize = cv2.resize(image, (dst_width, dst_height))\n",
    "        newimage = np.zeros(shape = (dstshape[1], dstshape[0], image.shape[2]), dtype = np.uint8) + padValue\n",
    "        newimage[origin[0]:origin[0]+dst_height, origin[1]:origin[1]+dst_width, :] = image_resize\n",
    "        bbx = [origin[1], origin[0], origin[1]+dst_width, origin[0]+dst_height] # x1,y1,x2,y2\n",
    "    else:\n",
    "        image_resize = cv2.resize(image, (dst_width, dst_height),  interpolation = cv2.INTER_NEAREST)\n",
    "        newimage = np.zeros(shape = (dstshape[1], dstshape[0]), dtype = np.uint8)\n",
    "        newimage[origin[0]:origin[0]+height, origin[1]:origin[1]+width] = image_resize\n",
    "        bbx = [origin[1], origin[0], origin[1]+dst_width, origin[0]+dst_height] # x1,y1,x2,y2\n",
    "    return newimage, bbx\n",
    "\n",
    "def syn(img_out, img_orig, fw ,fh, background):\n",
    "    # classMap_numpy = img_out[0].max(0)[1].byte().data.cpu().numpy()\n",
    "    classMap_numpy = np.empty((224, 224), dtype=float)\n",
    "    print(img_out[0].shape)\n",
    "    print(img_out[0, :, :, 0])\n",
    "    print(\"\\n\\n\\n\")\n",
    "    print(img_out[0, :, :, 1])\n",
    "    for i in range(224):\n",
    "        for j in range(224):\n",
    "            if img_out[0][i][j][1] > img_out[0][i][j][0]:\n",
    "                classMap_numpy[i][j] = 255\n",
    "            else:\n",
    "                classMap_numpy[i][j] = 0\n",
    "\n",
    "    # classMap_numpy = np.where(img_out[0] == np.max(img_out[0], axis=-1))[0]\n",
    "    # print(classMap_numpy.shape)\n",
    "    classMap_numpy=np.repeat(classMap_numpy[..., np.newaxis], 3, axis=2)\n",
    "    idx_fg = cv2.resize(classMap_numpy, (fw, fh))\n",
    "    cv2.imwrite(\"alpha.jpg\", idx_fg)\n",
    "    # print(img_orig.shape, idx_fg.shape, background.shape)\n",
    "    # idx_fg = cv2.cvtColor(idx_fg, cv2.COLOR_GRAY2BGR)\n",
    "    # seg_img=img_orig*idx_fg+background*(1-idx_fg)\n",
    "    # return seg_img\n",
    "    return None\n",
    "\n",
    "def generate_input(exp_args, inputs, prior=None):\n",
    "    inputs_norm = Normalize_Img(inputs, scale=exp_args.img_scale, mean=exp_args.img_mean, val=exp_args.img_val)\n",
    "    \n",
    "    if exp_args.video == True:\n",
    "        if prior is None:\n",
    "            prior = np.zeros((exp_args.input_height, exp_args.input_width, 1))\n",
    "            inputs_norm = np.c_[inputs_norm, prior]\n",
    "        else:\n",
    "            prior = prior.reshape(exp_args.input_height, exp_args.input_width, 1)\n",
    "            inputs_norm = np.c_[inputs_norm, prior]\n",
    "       \n",
    "    inputs = np.transpose(inputs_norm, (2, 0, 1))\n",
    "    return np.array(inputs, dtype=np.float32)\n",
    "\n",
    "def pred_single(model, exp_args, img_ori, prior=None):\n",
    "    in_shape = img_ori.shape\n",
    "#     img, bbx = resize_padding(img_ori, [exp_args.input_height, exp_args.input_width], padValue=exp_args.padding_color)\n",
    "    image_resize = cv2.resize(img_ori, (224, 224))\n",
    "\n",
    "#     in_ = generate_input(exp_args, img, prior)\n",
    "    inputs_norm = Normalize_Img(image_resize, scale=exp_args.img_scale, mean=exp_args.img_mean, val=exp_args.img_val)\n",
    "    in_ = inputs_norm[np.newaxis, :, :, :]\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        tf.global_variables_initializer().run()\n",
    "        output_graph_def = tf.GraphDef()\n",
    "        with open(\"../myTrain/Model/result.pb\", \"rb\") as f:\n",
    "            print(\"Loading pb\")\n",
    "            output_graph_def.ParseFromString(f.read())\n",
    "            _ = tf.import_graph_def(output_graph_def, name=\"\")\n",
    "            \n",
    "#         saver=tf.train.import_meta_graph(\"../myTrain/Model/result1950.meta\")\n",
    "#         saver.restore(sess, \"../myTrain/Model/result1950\")\n",
    "        graph = tf.get_default_graph()\n",
    "        x = graph.get_tensor_by_name('Inputs/x_input:0')\n",
    "        y = graph.get_tensor_by_name('result:0')\n",
    "        img_out = sess.run(y, feed_dict={x:in_})\n",
    "    \n",
    "    predimg = img_out[0,:,:,1]\n",
    "#     out = predimg[bbx[1]:bbx[3], bbx[0]:bbx[2]]\n",
    "    out = predimg\n",
    "    out = cv2.resize(out, (in_shape[1], in_shape[0]))\n",
    "    return out, predimg\n",
    "\n",
    "def image_test(model, mean, std, image_name, background):\n",
    "    \n",
    "    image_path = image_name\n",
    "    imgW, imgH = 224, 224\n",
    "    \n",
    "    img = cv2.imread(\"/home/yupeng/Program/python/Data/EG1800/Images/00001.png\")\n",
    "    fh ,fw=img.shape[:2]\n",
    "    img_orig, background, img_tensor=preprocess(img, fw, fh, background, imgW, imgH, mean, std)\n",
    "    stime=time.time()\n",
    "\n",
    "    # with torch.no_grad():\n",
    "    #     img_variable = torch.autograd.Variable(img_tensor)            \n",
    "    #     img_out = model(img_variable)\n",
    "    with tf.Session() as sess:\n",
    "        input_x = img_tensor.cpu().detach().numpy()\n",
    "        input_x = np.transpose(input_x, (0, 2, 3, 1))\n",
    "        saver=tf.train.import_meta_graph(\"../myTrain/Model/result154.meta\")\n",
    "        saver.restore(sess, \"../myTrain/Model/result154\")\n",
    "        graph = tf.get_default_graph()\n",
    "        \n",
    "        # writer = tf.summary.FileWriter(\"logs\", graph)\n",
    "        # writer.close()\n",
    "        # for op in graph.get_operations():\n",
    "        #     print(op.name)\n",
    "        x = graph.get_tensor_by_name('Inputs/x_input:0')\n",
    "        y = graph.get_tensor_by_name('Output/result:0')\n",
    "        img_out = sess.run(y, feed_dict={x:input_x})\n",
    "        \n",
    "    etime=time.time()\n",
    "    print(\"etime-stime:\",etime-stime)\n",
    "    \n",
    "    result=syn(img_out,img_orig, fw, fh, background)\n",
    "   \n",
    "\n",
    "    # cv2.imwrite(\"result.jpg\", result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========> loading config <============\n",
      "('config path: ', '/home/yupeng/Program/python/PortraitNet/config/model_mobilenetv2_without_auxiliary_losses.yaml')\n",
      "finish load PortraitNet ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yupeng/anaconda3/envs/py27/lib/python2.7/site-packages/ipykernel_launcher.py:6: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "print ('===========> loading config <============')\n",
    "config_path = '/home/yupeng/Program/python/PortraitNet/config/model_mobilenetv2_without_auxiliary_losses.yaml'\n",
    "print (\"config path: \", config_path)\n",
    "with open(config_path, 'rb') as f:\n",
    "    cont = f.read()\n",
    "cf = load(cont)\n",
    "\n",
    "exp_args = edict()\n",
    "\n",
    "exp_args.istrain = cf['istrain']  # set the mode\n",
    "exp_args.task = cf['task']  # only support 'seg' now\n",
    "exp_args.datasetlist = cf['datasetlist']\n",
    "exp_args.model_root = cf['model_root']\n",
    "exp_args.data_root = cf['data_root']\n",
    "exp_args.file_root = cf['file_root']\n",
    "\n",
    "# the height of input images, default=224\n",
    "exp_args.input_height = cf['input_height']\n",
    "# the width of input images, default=224\n",
    "exp_args.input_width = cf['input_width']\n",
    "\n",
    "# if exp_args.video=True, add prior channel for input images, default=False\n",
    "exp_args.video = cf['video']\n",
    "# the probability to set empty prior channel, default=0.5\n",
    "exp_args.prior_prob = cf['prior_prob']\n",
    "\n",
    "# whether to add boundary auxiliary loss, default=False\n",
    "exp_args.addEdge = cf['addEdge']\n",
    "# the weight of boundary auxiliary loss, default=0.1\n",
    "exp_args.edgeRatio = cf['edgeRatio']\n",
    "# whether to add consistency constraint loss, default=False\n",
    "exp_args.stability = cf['stability']\n",
    "# whether to use KL loss in consistency constraint loss, default=True\n",
    "exp_args.use_kl = cf['use_kl']\n",
    "# temperature in consistency constraint loss, default=1\n",
    "exp_args.temperature = cf['temperature']\n",
    "# the weight of consistency constraint loss, default=2\n",
    "exp_args.alpha = cf['alpha']\n",
    "\n",
    "# input normalization parameters\n",
    "exp_args.padding_color = cf['padding_color']\n",
    "exp_args.img_scale = cf['img_scale']\n",
    "# BGR order, image mean, default=[103.94, 116.78, 123.68]\n",
    "exp_args.img_mean = cf['img_mean']\n",
    "# BGR order, image val, default=[1/0.017, 1/0.017, 1/0.017]\n",
    "exp_args.img_val = cf['img_val']\n",
    "\n",
    "# whether to use pretian model to init portraitnet\n",
    "exp_args.init = cf['init']\n",
    "# whether to continue training\n",
    "exp_args.resume = cf['resume']\n",
    "\n",
    "# if exp_args.useUpsample==True, use nn.Upsample in decoder, else use nn.ConvTranspose2d\n",
    "exp_args.useUpsample = cf['useUpsample']\n",
    "# if exp_args.useDeconvGroup==True, set groups=input_channel in nn.ConvTranspose2d\n",
    "exp_args.useDeconvGroup = cf['useDeconvGroup']\n",
    "\n",
    "# img_ori = cv2.imread(\"/home/yupeng/Program/python/Data/EG1800/Images/00457.png\")\n",
    "\n",
    "import model_mobilenetv2_seg_small_tf as modellib\n",
    "netmodel = modellib.MobileNetV2(n_class=2,\n",
    "                                addEdge=exp_args.addEdge,\n",
    "                                channelRatio=1.0,\n",
    "                                minChannel=16)\n",
    "print (\"finish load PortraitNet ...\")\n",
    "\n",
    "# with tf.variable_scope('Inputs'):\n",
    "#     x = tf.placeholder(dtype=tf.float32, shape=[None, 224, 224, 3], name='x_input')\n",
    "#     y = tf.placeholder(dtype=tf.int64, shape=[None, 224, 224], name='y_input')\n",
    "\n",
    "# pred = netmodel.build(x)\n",
    "\n",
    "mean=[117.46679, 125.55083, 137.98093]\n",
    "std=[63.793976, 63.89187,  65.8852  ]\n",
    "# model , model_file,\n",
    "# model.load_state_dict(torch.load(Max_name, \"cpu\"))# Load model\n",
    "# model.eval()\n",
    "# background = cv2.imread('syn_bg.jpg')\n",
    "# image_test(netmodel, mean, std, image_name, background)\n",
    "# netmodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 600)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_ori = cv2.imread(\"/home/yupeng/Program/python/Data/EG1800/Images/00001.png\")\n",
    "\n",
    "background = img_ori.copy()\n",
    "background = cv2.blur(background, (17,17))\n",
    "\n",
    "prior = None\n",
    "height, width, _ = img_ori.shape\n",
    "\n",
    "alphargb, pred = pred_single(netmodel, exp_args, img_ori, prior)\n",
    "# print(alphargb)\n",
    "\n",
    "print(alphargb.shape)\n",
    "\n",
    "# maxnow = -1e9\n",
    "# minnow = 1e9\n",
    "\n",
    "# for i in range(alphargb.shape[0]):\n",
    "#     for j in range(alphargb.shape[1]):\n",
    "#         if alphargb[i][j] < minnow:\n",
    "#             minnow = alphargb[i][j]\n",
    "#         if alphargb[i][j] > maxnow:\n",
    "#             maxnow = alphargb[i][j]\n",
    "\n",
    "# print(minnow, maxnow)\n",
    "\n",
    "# for i in range(800):\n",
    "#     for j in range(600):\n",
    "#         if ((alphargb[i][j] - minnow) / (maxnow - minnow) > 0.5):\n",
    "#             alphargb[i][j] = 1\n",
    "#         else:\n",
    "#             alphargb[i][j] = 0\n",
    "\n",
    "plt.imshow(alphargb)\n",
    "plt.show()\n",
    "\n",
    "alphargb = cv2.cvtColor(alphargb, cv2.COLOR_GRAY2BGR)\n",
    "result = np.uint8(img_ori * alphargb + background * (1-alphargb))\n",
    "cv2.imwrite(\"result.jpg\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background blur for single image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_ori = cv2.imread(\"/home/yupeng/Program/python/Data/EG1800/Images/00001.png\")\n",
    "# # mask_ori = cv2.imread(\"/home/yupeng/Program/python/Data/EG1800/Labels/00457.png\")\n",
    "\n",
    "# prior = None\n",
    "# height, width, _ = img_ori.shape\n",
    "\n",
    "# background = img_ori.copy()\n",
    "# background = cv2.blur(background, (17,17))\n",
    "\n",
    "# alphargb, pred = pred_single(netmodel_video, exp_args, img_ori, prior)\n",
    "# # print(alphargb)\n",
    "# plt.imshow(pred)\n",
    "# plt.show()\n",
    "# print alphargb.shape\n",
    "\n",
    "# alphargb = cv2.cvtColor(alphargb, cv2.COLOR_GRAY2BGR)\n",
    "# result = np.uint8(img_ori * alphargb + background * (1-alphargb))\n",
    "\n",
    "# myImg = np.ones((height, width*2 + 20, 3)) * 255\n",
    "# myImg[:, :width, :] = img_ori\n",
    "# myImg[:, width+20:, :] = result\n",
    "\n",
    "# plt.imshow(myImg[:,:,::-1]/255)\n",
    "# plt.yticks([])\n",
    "# plt.xticks([])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### video test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('cnt: ', 100)\n",
      "('cnt: ', 200)\n",
      "('cnt: ', 300)\n",
      "('cnt: ', 400)\n",
      "('cnt: ', 500)\n",
      "('cnt: ', 600)\n",
      "finish\n"
     ]
    }
   ],
   "source": [
    "# videofile = 'douyu_origin.mp4'\n",
    "# videoCapture = cv2.VideoCapture(videofile)  \n",
    "# size = ((int(videoCapture.get(cv2.CAP_PROP_FRAME_WIDTH))+20)*3, int(videoCapture.get(cv2.CAP_PROP_FRAME_HEIGHT)))  \n",
    "# videoWriter = cv2.VideoWriter('result.mp4', cv2.VideoWriter_fourcc(*'MJPG'), 20, size)  \n",
    "\n",
    "# success, frame = videoCapture.read()\n",
    "# cnt = 1\n",
    "# while success:\n",
    "#     if cnt == 1:\n",
    "#         prior = None # first frame\n",
    "#     else:\n",
    "#         prior = pred_video\n",
    "    \n",
    "#     alpha_video, pred_video = pred_single(netmodel_video, exp_args, frame, prior)\n",
    "#     alpha_image, pred_image = pred_single(netmodel_video, exp_args, frame, None)\n",
    "    \n",
    "#     def blend(frame, alpha):\n",
    "#         background = np.zeros(frame.shape) + [255, 255, 255]\n",
    "#         alphargb = cv2.cvtColor(alpha, cv2.COLOR_GRAY2BGR)\n",
    "#         result = np.uint8(frame * alphargb + background * (1-alphargb))\n",
    "#         return frame, alphargb*255, result\n",
    "    \n",
    "#     _, alphargb_video, _ = blend(frame, alpha_video)\n",
    "#     _, alphargb_image, _ = blend(frame, alpha_image)\n",
    "    \n",
    "#     padding = np.ones((frame.shape[0], 20, 3), dtype = np.uint8)*255\n",
    "#     result = np.uint8(np.hstack((frame, padding,\n",
    "#                                  alphargb_video, padding,\n",
    "#                                  alphargb_image, padding)))\n",
    "#     videoWriter.write(result)\n",
    "#     success, frame = videoCapture.read()\n",
    "#     cnt += 1\n",
    "    \n",
    "#     if cnt % 100 == 0:\n",
    "#         print (\"cnt: \", cnt)\n",
    "    \n",
    "# videoWriter.release()\n",
    "\n",
    "# print \"finish\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
