{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.nn import DataParallel\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import graph_util\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from easydict import EasyDict as edict\n",
    "from yaml import load\n",
    "\n",
    "import sys\n",
    "sys.path.append('../data/')\n",
    "sys.path.append('../util/')\n",
    "sys.path.append('../model/')\n",
    "\n",
    "import datasets\n",
    "from datasets import Human\n",
    "from data_aug import Normalize_Img, Anti_Normalize_Img\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcIOU(img, mask):\n",
    "    sum1 = img + mask\n",
    "    sum1[sum1>0] = 1\n",
    "    sum2 = img + mask\n",
    "    sum2[sum2<2] = 0\n",
    "    sum2[sum2>=2] = 1\n",
    "    if np.sum(sum1) == 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 1.0*np.sum(sum2)/np.sum(sum1)\n",
    "\n",
    "def test(dataLoader, netmodel, exp_args):\n",
    "    # switch to eval mode\n",
    "    iou = 0\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        tf.global_variables_initializer().run()\n",
    "        output_graph_def = tf.GraphDef()\n",
    "        with open(\"../myTrain/Model/teapot.pb\", \"rb\") as f:\n",
    "            print(\"Loading pb\")\n",
    "            output_graph_def.ParseFromString(f.read())\n",
    "            _ = tf.import_graph_def(output_graph_def, name=\"\")            \n",
    "            graph = tf.get_default_graph()\n",
    "            # saver=tf.train.import_meta_graph(\"../myTrain/Model/result1950.meta\")\n",
    "            # saver.restore(sess, \"../myTrain/Model/result1950\")\n",
    "            x = graph.get_tensor_by_name('Inputs/x_input:0')\n",
    "            y = graph.get_tensor_by_name('result:0')\n",
    "        \n",
    "        for i, (input_ori, input, edge, mask) in enumerate(dataLoader):  \n",
    "            # print(mask.shape)\n",
    "            input_ori_var = Variable(input_ori.cuda())\n",
    "            input_var = Variable(input.cuda())\n",
    "            edge_var = Variable(edge.cuda())\n",
    "            mask_var = Variable(mask.cuda())\n",
    "            input_x = input.cpu().detach().numpy()\n",
    "            input_x = np.transpose(input_x, (0, 2, 3, 1))\n",
    "            \n",
    "            img_out = sess.run(y, feed_dict={x:input_x})\n",
    "\n",
    "            pred = img_out[0,:,:,1]\n",
    "            pred[pred>0.5] = 1\n",
    "            pred[pred<=0.5] = 0\n",
    "            iou += calcIOU(pred, mask_var[0].data.cpu().numpy())\n",
    "        \n",
    "    print len(dataLoader)\n",
    "    return iou/len(dataLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish load config file ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yupeng/anaconda3/envs/py27/lib/python2.7/site-packages/ipykernel_launcher.py:9: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "# load model-1 or model-2: trained with two auxiliary losses (without prior channel)\n",
    "config_path = '../config/model_mobilenetv2_without_auxiliary_losses.yaml'\n",
    "\n",
    "# load model-3: trained with prior channel \n",
    "# config_path = '../config/model_mobilenetv2_with_prior_channel.yaml'\n",
    "\n",
    "with open(config_path,'rb') as f:\n",
    "    cont = f.read()\n",
    "cf = load(cont)\n",
    "\n",
    "print ('finish load config file ...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========> loading data <===========\n",
      "('datasetlist: ', ['EG1800'])\n",
      "39\n",
      "39\n",
      "finish load dataset ...\n",
      "===========> loading model <===========\n",
      "finish load PortraitNet ...\n"
     ]
    }
   ],
   "source": [
    "print ('===========> loading data <===========')\n",
    "exp_args = edict()    \n",
    "exp_args.istrain = False\n",
    "exp_args.task = cf['task']\n",
    "exp_args.datasetlist = cf['datasetlist'] # ['EG1800', ATR', 'MscocoBackground', 'supervisely_face_easy']\n",
    "print (\"datasetlist: \", exp_args.datasetlist)\n",
    "\n",
    "exp_args.model_root = cf['model_root'] \n",
    "exp_args.data_root = cf['data_root']\n",
    "exp_args.file_root = cf['file_root']\n",
    "\n",
    "# the height of input images, default=224\n",
    "exp_args.input_height = cf['input_height']\n",
    "# the width of input images, default=224\n",
    "exp_args.input_width = cf['input_width']\n",
    "\n",
    "# if exp_args.video=True, add prior channel for input images, default=False\n",
    "exp_args.video = cf['video']\n",
    "# the probability to set empty prior channel, default=0.5\n",
    "exp_args.prior_prob = cf['prior_prob']\n",
    "\n",
    "# whether to add boundary auxiliary loss, default=False\n",
    "exp_args.addEdge = cf['addEdge']\n",
    "# whether to add consistency constraint loss, default=False\n",
    "exp_args.stability = cf['stability']\n",
    "\n",
    "# input normalization parameters\n",
    "exp_args.padding_color = cf['padding_color']\n",
    "exp_args.img_scale = cf['img_scale']\n",
    "# BGR order, image mean, default=[103.94, 116.78, 123.68]\n",
    "exp_args.img_mean = cf['img_mean']\n",
    "# BGR order, image val, default=[1/0.017, 1/0.017, 1/0.017]\n",
    "exp_args.img_val = cf['img_val'] \n",
    "\n",
    "# if exp_args.useUpsample==True, use nn.Upsample in decoder, else use nn.ConvTranspose2d\n",
    "exp_args.useUpsample = cf['useUpsample'] \n",
    "# if exp_args.useDeconvGroup==True, set groups=input_channel in nn.ConvTranspose2d\n",
    "exp_args.useDeconvGroup = cf['useDeconvGroup'] \n",
    "\n",
    "exp_args.init = False\n",
    "exp_args.resume = True\n",
    "\n",
    "dataset_test = Human(exp_args)\n",
    "print len(dataset_test)\n",
    "dataLoader_test = torch.utils.data.DataLoader(dataset_test, batch_size=1, shuffle=False, num_workers=1)\n",
    "print len(dataLoader_test)\n",
    "print (\"finish load dataset ...\")\n",
    "\n",
    "print ('===========> loading model <===========')\n",
    "import model_mobilenetv2_seg_small_tf as modellib\n",
    "netmodel = modellib.MobileNetV2(n_class=2,\n",
    "                                addEdge=exp_args.addEdge,\n",
    "                                channelRatio=1.0,\n",
    "                                minChannel=16)\n",
    "print (\"finish load PortraitNet ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pb\n",
      "39\n",
      "('mean iou: ', 0.42608315170646505)\n"
     ]
    }
   ],
   "source": [
    "acc = test(dataLoader_test, netmodel, exp_args)\n",
    "print (\"mean iou: \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
